# Sistema de Detecci√≥n de Fraude en Transacciones Financieras

Pipeline de datos end-to-end utilizando el ecosistema de Apache Kafka para procesar transacciones financieras en tiempo real y detectar posibles casos de fraude.

##  Estructura del Proyecto

```
fraud_detector_r4/
‚îú‚îÄ‚îÄ connectors/                      # Configuraciones de Kafka Connect
‚îÇ   ‚îú‚îÄ‚îÄ csv-source-connector.json   # Source connector para archivos CSV
‚îÇ   ‚îú‚îÄ‚îÄ postgres-sink-connector.json # Sink connector para PostgreSQL
‚îÇ   ‚îî‚îÄ‚îÄ fraud-alerts-sink-connector.json # Sink connector para alertas de fraude
‚îú‚îÄ‚îÄ data/                            # Directorio de datos
‚îÇ   ‚îú‚îÄ‚îÄ input/                       # Archivos CSV de entrada
‚îÇ   ‚îú‚îÄ‚îÄ processed/                   # Archivos CSV procesados
‚îÇ   ‚îî‚îÄ‚îÄ error/                       # Archivos con errores
‚îú‚îÄ‚îÄ ksqldb/                          # Scripts de ksqlDB
‚îÇ   ‚îú‚îÄ‚îÄ 01-create-streams.sql       # Creaci√≥n de streams base
‚îÇ   ‚îú‚îÄ‚îÄ 02-fraud-detection.sql      # Reglas de detecci√≥n de fraude
‚îÇ   ‚îî‚îÄ‚îÄ 03-aggregations.sql         # Agregaciones y estad√≠sticas
‚îú‚îÄ‚îÄ postgres/                        # Scripts de PostgreSQL
‚îÇ   ‚îî‚îÄ‚îÄ init-db.sql                 # Inicializaci√≥n de base de datos
‚îú‚îÄ‚îÄ schemas/                         # JSON Schemas para Schema Registry
‚îÇ   ‚îú‚îÄ‚îÄ transaction-value-schema.json # Schema de transacciones
‚îÇ   ‚îî‚îÄ‚îÄ README.md                    # Documentaci√≥n de schemas
‚îú‚îÄ‚îÄ scripts/                         # Scripts de automatizaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ create-env.sh               # Creaci√≥n interactiva de .env
‚îÇ   ‚îú‚îÄ‚îÄ deploy-connectors.sh        # Despliegue de conectores
‚îÇ   ‚îú‚îÄ‚îÄ register-schema.sh          # Registro de schemas en Schema Registry
‚îÇ   ‚îú‚îÄ‚îÄ run-ksql-scripts.sh         # Ejecuci√≥n de scripts ksqlDB
‚îÇ   ‚îú‚îÄ‚îÄ wait-for-services.sh        # Espera de servicios
‚îÇ   ‚îú‚îÄ‚îÄ test-pipeline.sh            # Prueba completa del pipeline
‚îÇ   ‚îî‚îÄ‚îÄ validate-data-flow.sh       # Validaci√≥n del flujo de datos
‚îú‚îÄ‚îÄ docker-compose.yml               # Configuraci√≥n de contenedores
‚îú‚îÄ‚îÄ generate_test_data.py            # Generador de datos de prueba
‚îú‚îÄ‚îÄ generate_fraud_test_data.py      # Generador de casos espec√≠ficos de fraude
‚îú‚îÄ‚îÄ setup.sh                         # Script de configuraci√≥n inicial *
‚îú‚îÄ‚îÄ demo.sh                          # Script de demostraci√≥n del pipeline *
‚îî‚îÄ‚îÄ README.md                        # Este archivo
```

##  Formato de Datos CSV

El sistema procesa archivos CSV con la siguiente estructura:

| Campo            | Tipo      | Descripci√≥n                                                  |
|-----------------|-----------|--------------------------------------------------------------|
| transaction_id  | VARCHAR   | ID √∫nico de transacci√≥n (ej: TXN_000001, FRAUD_001)        |
| account_id      | VARCHAR   | ID de cuenta (ej: ACC_0001)                                 |
| timestamp       | TIMESTAMP | Fecha y hora (formato: yyyy-MM-dd HH:mm:ss)                 |
| amount          | DECIMAL   | Monto de la transacci√≥n                                      |
| merchant_name   | VARCHAR   | Nombre del comercio                                          |
| transaction_type| VARCHAR   | Tipo: PURCHASE, WITHDRAWAL, TRANSFER, PAYMENT               |
| latitude        | DOUBLE    | Latitud de la ubicaci√≥n de la transacci√≥n                   |
| longitude       | DOUBLE    | Longitud de la ubicaci√≥n de la transacci√≥n                  |
| channel         | VARCHAR   | Canal: ATM, MOBILE, ONLINE, POS                             |
| status          | VARCHAR   | Estado: APPROVED, PENDING, DECLINED                         |

### Ejemplo de datos:

```csv
transaction_id,account_id,timestamp,amount,merchant_name,transaction_type,latitude,longitude,channel,status
TXN_000001,ACC_0001,2024-10-01 10:30:00,125.50,Walmart Supercenter,PURCHASE,40.7128,-74.0060,POS,APPROVED
FRAUD_001,ACC_0010,2024-10-01 15:45:00,15000.00,Amazon Web Services,PURCHASE,34.0522,-118.2437,ONLINE,APPROVED
TXN_000002,ACC_0002,2024-10-01 11:20:00,45.75,Starbucks Coffee,PURCHASE,41.8781,-87.6298,MOBILE,APPROVED
```

##  Inicio R√°pido

### Instalaci√≥n en 2 Pasos

#### Paso 1: Configurar el Sistema

```bash
# Configurar variables de entorno (primera vez)
./scripts/create-env.sh

# Configurar y levantar todo el pipeline
chmod +x setup.sh
./setup.sh
```

El script `setup.sh` realizar√° autom√°ticamente:
- Levantamiento de servicios Docker
- Espera de servicios disponibles
- Registro de schemas en Schema Registry
- Despliegue de conectores de Kafka Connect
- Ejecuci√≥n de scripts de ksqlDB

#### Paso 2: Ejecutar la Demo

```bash
# Ejecutar demostraci√≥n completa del pipeline
chmod +x demo.sh
./demo.sh
```

El script `demo.sh`:
- Verifica que el sistema est√© configurado
- Genera datos de prueba con casos espec√≠ficos de fraude
- Procesa los datos a trav√©s del pipeline
- Muestra estad√≠sticas y resultados en tiempo real
- Valida el flujo completo de datos

### Flujo Manual (Alternativo)

Si prefieres ejecutar los pasos manualmente:

```bash
# 1. Levantar servicios
docker-compose up -d

# 2. Esperar servicios
./scripts/wait-for-services.sh

# 3. Registrar schema
./scripts/register-schema.sh schemas/transaction-value-schema.json trx-fraud-transactions-value

# 4. Desplegar conectores
./scripts/deploy-connectors.sh

# 5. Ejecutar scripts ksqlDB
./scripts/run-ksql-scripts.sh

# 6. Generar datos de prueba
python3 generate_fraud_test_data.py

# 7. Validar pipeline
sleep 20
./scripts/validate-data-flow.sh
```

### Generar Datos Personalizados

```bash
# Generar 1000 transacciones (5% de fraude por defecto)
python generate_test_data.py -t 1000 -o data/input/transactions.csv

# Generar con tasa de fraude personalizada
python generate_test_data.py -t 5000 --fraud-rate 0.08 -o data/input/test_data.csv

# Ver ayuda
python generate_test_data.py --help
```

**Nota:** Por defecto, el script agrega autom√°ticamente un timestamp al nombre del archivo para evitar sobrescribir archivos existentes. Usa la opci√≥n `--no-timestamp` si deseas usar el nombre exacto especificado.

### Monitorear el Sistema

**Kafka Control Center:**
- URL: http://localhost:9021
- Monitorea topics, conectores y rendimiento

**PostgreSQL:**
```bash
docker exec -it postgres psql -U kafka_user -d fraud_detection
```

**ksqlDB CLI:**
```bash
docker exec -it ksqldb-cli ksql http://ksqldb-server:8088
```

##  Scripts Automatizados

El proyecto incluye scripts bash para automatizar el setup y operaci√≥n del pipeline. **Ver [`scripts/README.md`](scripts/README.md) para documentaci√≥n completa.**

### Scripts de Setup
- **`scripts/create-env.sh`**: Creaci√≥n interactiva del archivo `.env`
- **`scripts/wait-for-services.sh`**: Espera a que todos los servicios est√©n disponibles
- **`scripts/register-schema.sh`**: Registra schemas en Schema Registry
- **`scripts/deploy-connectors.sh`**: Despliega conectores de Kafka Connect
- **`scripts/run-ksql-scripts.sh`**: Ejecuta scripts de ksqlDB

### Scripts de Validaci√≥n
- **`scripts/validate-data-flow.sh`**: Valida el flujo completo de datos
- **`scripts/test-pipeline.sh`**: Ejecuta prueba completa con datos generados

### Generadores de Datos
- **`generate_test_data.py`**: Genera datos sint√©ticos de prueba
- **`generate_fraud_test_data.py`**: Genera casos espec√≠ficos para cada regla

### Uso R√°pido
```bash
# Setup completo
docker-compose up -d && \
./scripts/wait-for-services.sh && \
./scripts/register-schema.sh schemas/transaction-value-schema.json trx-fraud-transactions-value && \
./scripts/deploy-connectors.sh && \
./scripts/run-ksql-scripts.sh

# Prueba con datos espec√≠ficos
python3 generate_fraud_test_data.py
sleep 15
./scripts/validate-data-flow.sh
```

##  Reglas de Detecci√≥n de Fraude

El sistema implementa **5 reglas principales** de detecci√≥n de fraude en tiempo real:

### 1. Transacciones de Alto Valor
- **Condici√≥n:** Monto > $10,000
- **Severidad:** HIGH
- **Topic:** `fraud-high-value`
- **Campos guardados:** `transaction_id`, `account_id`, `amount`, y todos los detalles de la transacci√≥n

### 2. Frecuencia Anormal
- **Condici√≥n:** M√°s de 5 transacciones en 5 minutos
- **Severidad:** HIGH
- **Topic:** `fraud-high-frequency-table`
- **Campos guardados:** `account_id`, `transaction_ids` (array), `transaction_count`, `total_amount`, `window_start`, `window_end`

### 3. M√∫ltiples Ubicaciones Simult√°neas
- **Condici√≥n:** M√°s de 2 ubicaciones diferentes en 10 minutos
- **Severidad:** HIGH
- **Topic:** `fraud-multiple-locations-table`
- **Campos guardados:** `account_id`, `transaction_ids` (array), `locations` (array), `unique_locations`, `window_start`, `window_end`

### 4. Cambios Dr√°sticos de Comportamiento
- **Condici√≥n:** Transacci√≥n 3x superior al promedio hist√≥rico (an√°lisis en ventana de 1 hora)
- **Severidad:** MEDIUM
- **Topic:** `account-avg-amount-table`
- **Campos guardados:** `account_id`, `avg_amount`, `max_amount`, `min_amount`, `transaction_count`

### 5. Horarios Inusuales
- **Condici√≥n:** Transacciones entre 2AM-5AM
- **Severidad:** LOW
- **Topic:** `fraud-unusual-time`
- **Campos guardados:** `transaction_id`, `account_id`, `hour_of_day`, y todos los detalles de la transacci√≥n

##  Agregaciones y Estad√≠sticas

El sistema genera m√∫ltiples streams de agregaci√≥n:

- **account_statistics:** Estad√≠sticas por cuenta (ventana 1 hora)
- **merchant_statistics:** Estad√≠sticas por comerciante (ventana 1 hora)
- **location_statistics:** Estad√≠sticas por ubicaci√≥n (ventana 1 hora)
- **channel_statistics:** Estad√≠sticas por canal (ventana 1 hora)
- **transaction_type_statistics:** Estad√≠sticas por tipo de transacci√≥n
- **real_time_volume:** Volumen total en tiempo real (ventana 5 minutos)
- **velocity_check:** Verificaci√≥n de velocidad (ventana 1 minuto)
- **daily_patterns:** Patrones por d√≠a de la semana

## üóÑ Base de Datos PostgreSQL

### Tablas Principales

1. **transactions:** Todas las transacciones procesadas
2. **fraud_alerts:** Alertas de fraude detectadas
3. **account_statistics:** Estad√≠sticas agregadas por cuenta
4. **merchant_statistics:** Estad√≠sticas agregadas por comerciante
5. **location_statistics:** Estad√≠sticas agregadas por ubicaci√≥n
6. **channel_statistics:** Estad√≠sticas agregadas por canal

### Vistas √ötiles

- **v_account_summary:** Resumen por cuenta
- **v_fraud_by_account:** Alertas de fraude por cuenta
- **v_suspicious_merchants:** Comerciantes con m√°s fraude
- **v_recent_fraud_transactions:** Transacciones fraudulentas recientes
- **v_daily_statistics:** Estad√≠sticas diarias
- **v_hourly_patterns:** Patrones horarios

### Funciones

```sql
-- Obtener transacciones recientes de una cuenta
SELECT * FROM get_account_recent_transactions('ACC_0001', 10);

-- Calcular tasa de fraude
SELECT * FROM calculate_fraud_rate();
```

##  Consultas ksqlDB √ötiles

```sql
-- Ver todas las transacciones
SELECT * FROM transactions_stream EMIT CHANGES LIMIT 10;

-- Ver transacciones enriquecidas
SELECT * FROM transactions_stream_enriched EMIT CHANGES;

-- Ver alertas de fraude consolidadas
SELECT * FROM fraud_alerts_consolidated EMIT CHANGES;

-- Ver estad√≠sticas de cuenta en tiempo real
SELECT * FROM account_statistics EMIT CHANGES;

-- Ver comerciantes m√°s activos
SELECT merchant_name, transaction_count, total_volume 
FROM merchant_statistics EMIT CHANGES;

-- Ver volumen en tiempo real
SELECT * FROM real_time_volume EMIT CHANGES;

-- Ver alertas de velocidad
SELECT * FROM velocity_alerts EMIT CHANGES;

-- Ver estad√≠sticas por canal
SELECT * FROM channel_statistics EMIT CHANGES;
```

##  Componentes Docker

- **Zookeeper:** Coordinaci√≥n de Kafka
- **Kafka Broker:** Servidor de mensajer√≠a
- **Schema Registry:** Registro de esquemas
- **Kafka Connect:** Framework de conectores
- **ksqlDB Server:** Motor de procesamiento de streams
- **ksqlDB CLI:** Cliente de l√≠nea de comandos
- **Control Center:** Interfaz web de monitoreo
- **PostgreSQL:** Base de datos persistente

##  Configuraci√≥n con Variables de Entorno

El proyecto utiliza **dos niveles** de configuraci√≥n con variables de entorno:

### 1. Variables Globales (`.env`)
Archivo √∫nico para variables compartidas entre scripts y herramientas.

### 2. Variables por Servicio (`env.d/*.env`)
Cada contenedor Docker tiene su propio archivo de variables en el directorio `env.d/`.

### Creaci√≥n de Archivos de Configuraci√≥n

#### Opci√≥n 1: Variables Globales (.env)
Para scripts y herramientas del proyecto:

```bash
# Script interactivo (recomendado)
./create-env.sh

# O copiar manualmente
cp env.template .env
```

El script `create-env.sh`:
-  Verifica si `.env` existe y crea backup si es necesario
-  Copia el template con todos los valores por defecto
-  Muestra las configuraciones importantes a personalizar
-  Permite editar el archivo inmediatamente
-  Proporciona pr√≥ximos pasos claros

#### Opci√≥n 2: Variables por Servicio (env.d/)
Para contenedores Docker - **YA EST√ÅN CREADOS Y LISTOS**:

Los archivos en `env.d/` ya est√°n configurados con valores por defecto. Solo necesitas modificarlos si:
- Cambias contrase√±as (especialmente `postgres.env`)
- Ajustas configuraci√≥n para producci√≥n
- Personalizas puertos o conexiones

```bash
# Ver archivos disponibles
ls -la env.d/

# Editar PostgreSQL (por ejemplo, cambiar contrase√±a)
nano env.d/postgres.env

# Editar Kafka
nano env.d/kafka.env
```

**Archivos disponibles:**
- `zookeeper.env` - Configuraci√≥n de Zookeeper
- `kafka.env` - Configuraci√≥n de Kafka Broker
- `schema-registry.env` - Schema Registry
- `kafka-connect.env` - Kafka Connect
- `ksqldb-server.env` - ksqlDB Server
- `postgres.env` - PostgreSQL  Cambiar contrase√±a en producci√≥n
- `adminer.env` - Adminer (UI PostgreSQL)
- `kafka-ui.env` - Kafka UI

 **Documentaci√≥n detallada:** Ver `env.d/README.md`

### Variables Principales por Ubicaci√≥n

#### Variables Globales (`.env`)
Usadas por scripts de setup y herramientas:

| Categor√≠a | Variable | Valor por Defecto | Ubicaci√≥n |
|-----------|----------|-------------------|-----------|
| **Topics** | `TRANSACTIONS_TOPIC` | trx-fraud-transactions | `.env` |
| | `FRAUD_ALERTS_TOPIC` | fraud-alerts | `.env` |
| | `TOPIC_PARTITIONS` | 3 | `.env` |
| **URLs** | `KAFKA_CONNECT_URL` | http://localhost:8083 | `.env` |
| | `KSQLDB_SERVER_URL` | http://localhost:8088 | `.env` |
| **Reintentos** | `MAX_RETRIES` | 30 | `.env` |
| | `RETRY_INTERVAL` | 2 | `.env` |

#### Variables por Servicio (env.d/)
Usadas por contenedores Docker:

| Servicio | Archivo | Variables Clave |
|----------|---------|-----------------|
| **Kafka** | `env.d/kafka.env` | `KAFKA_BROKER_ID`, `KAFKA_ADVERTISED_LISTENERS` |
| **PostgreSQL** | `env.d/postgres.env` | `POSTGRES_DB`, `POSTGRES_USER`, `POSTGRES_PASSWORD`  |
| **Kafka Connect** | `env.d/kafka-connect.env` | `CONNECT_BOOTSTRAP_SERVERS`, `CONNECT_GROUP_ID` |
| **ksqlDB** | `env.d/ksqldb-server.env` | `KSQL_BOOTSTRAP_SERVERS`, `KSQL_SERVICE_ID` |
| **Zookeeper** | `env.d/zookeeper.env` | `ZOOKEEPER_CLIENT_PORT` |
| **Schema Registry** | `env.d/schema-registry.env` | `SCHEMA_REGISTRY_HOST_NAME` |
| **Adminer** | `env.d/adminer.env` | `ADMINER_DEFAULT_SERVER` |
| **Kafka UI** | `env.d/kafka-ui.env` | `KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS` |

### Variables de Fraude (Documentaci√≥n)

Estas variables documentan los umbrales usados en las reglas de detecci√≥n:

```env
FRAUD_HIGH_VALUE_THRESHOLD=10000
FRAUD_HIGH_FREQUENCY_COUNT=5
FRAUD_HIGH_FREQUENCY_WINDOW=5
FRAUD_MULTIPLE_LOCATIONS_COUNT=2
FRAUD_MULTIPLE_LOCATIONS_WINDOW=10
FRAUD_BEHAVIOR_MULTIPLIER=3
FRAUD_UNUSUAL_TIME_START=2
FRAUD_UNUSUAL_TIME_END=5
FRAUD_UNUSUAL_TIME_AMOUNT=1000
```

### Personalizaci√≥n

#### Variables Globales
Para scripts y herramientas:

```bash
# Editar variables globales
nano .env
# Modificar variables seg√∫n necesites
```

#### Variables de Servicios Docker
Para configuraci√≥n de contenedores:

```bash
# Cambiar contrase√±a de PostgreSQL (IMPORTANTE en producci√≥n)
nano env.d/postgres.env
# Modificar: POSTGRES_PASSWORD=mi_contrase√±a_segura

# Ajustar configuraci√≥n de Kafka
nano env.d/kafka.env
# Modificar listeners si usas host remoto

# Personalizar Kafka Connect
nano env.d/kafka-connect.env
```

**Despu√©s de modificar archivos en `env.d/`:**
```bash
# Reiniciar servicios para aplicar cambios
docker-compose down
docker-compose up -d
```

### Uso de Variables

#### En Scripts
Los scripts cargan autom√°ticamente variables del archivo `.env` global:

- `setup.sh`: Script principal
- `scripts/deploy-connectors.sh`: Despliegue de conectores
- `scripts/wait-for-services.sh`: Espera de servicios
- `scripts/run-ksql-scripts.sh`: Ejecuci√≥n de ksqlDB

Si `.env` no existe, los scripts usan valores por defecto.

#### En Docker Compose
Los contenedores cargan variables desde archivos en `env.d/`:

```yaml
services:
  postgres:
    image: postgres:15-alpine
    env_file:
      - ./env.d/postgres.env  #  Variables espec√≠ficas del servicio
```

Cada contenedor solo tiene acceso a sus propias variables, mejorando la seguridad y organizaci√≥n.

##  Notas Importantes

1. **Archivo .env:** Crear siempre el archivo `.env` antes de iniciar (`cp env.template .env`)
2. **Formato de CSV:** El archivo debe tener encabezados y usar coma como delimitador
3. **Coordenadas:** Latitude y longitude deben ser n√∫meros decimales v√°lidos
4. **Timestamp:** Debe seguir el formato `yyyy-MM-dd HH:mm:ss`
5. **IDs de Fraude:** Las transacciones fraudulentas usan el prefijo `FRAUD_`
6. **Ubicaciones:** El sistema calcula ubicaciones como concatenaci√≥n de lat,lon
7. **Seguridad:** NO subir el archivo `.env` con contrase√±as reales a repositorios p√∫blicos

##  Flujo de Datos

```
CSV File ‚Üí Kafka Connect (Source) ‚Üí Kafka Topic (trx-fraud-transactions) 
    ‚Üì
ksqlDB Processing (Fraud Detection + Aggregations)
    ‚Üì
Multiple Kafka Topics (fraud-*, *-statistics)
    ‚Üì
Kafka Connect (Sink) ‚Üí PostgreSQL
```

##  Troubleshooting

### Ver logs de conectores
```bash
docker logs kafka-connect
```

### Ver logs de ksqlDB
```bash
docker logs ksqldb-server
```

### Verificar estado de conectores
```bash
curl http://localhost:8083/connectors
curl http://localhost:8083/connectors/csv-source-connector/status
```

### Reiniciar un conector
```bash
curl -X POST http://localhost:8083/connectors/csv-source-connector/restart
```

##  Recursos Adicionales

- [Documentaci√≥n de Kafka](https://kafka.apache.org/documentation/)
- [Documentaci√≥n de ksqlDB](https://docs.ksqldb.io/)
- [Kafka Connect](https://docs.confluent.io/platform/current/connect/index.html)
- [PostgreSQL](https://www.postgresql.org/docs/)

##  Casos de Uso

Este sistema es ideal para:

- Detecci√≥n de fraude en tiempo real
- An√°lisis de patrones de transacciones
- Monitoreo de actividad sospechosa
- Generaci√≥n de alertas autom√°ticas
- An√°lisis de comportamiento de clientes
- Reporting y analytics en tiempo real

## ‚ö° Rendimiento

- Procesamiento en tiempo real < 100ms
- Soporte para millones de transacciones/d√≠a
- Ventanas de agregaci√≥n configurables
- Escalabilidad horizontal con Kafka partitions

## üîê Seguridad

### Buenas Pr√°cticas

1. **Variables de Entorno:**
   - El archivo `.env` est√° en `.gitignore` por defecto
   - NUNCA subir `.env` con contrase√±as reales al repositorio
   - Usar `env.template` como referencia para otros desarrolladores

2. **Producci√≥n:**
   - Cambiar `POSTGRES_PASSWORD` a una contrase√±a segura
   - Usar Docker Secrets o Vault para gesti√≥n de secretos
   - Configurar autenticaci√≥n en Kafka (SASL/SSL)
   - Habilitar cifrado en tr√°nsito (SSL/TLS)

3. **Desarrollo:**
   - Las contrase√±as por defecto son solo para desarrollo local
   - No exponer puertos innecesarios al exterior
   - Revisar logs regularmente

4. **Sistema:**
   - Validaci√≥n de datos en conectores
   - Dead Letter Queue para errores
   - Logs de auditor√≠a en PostgreSQL
   - √çndices optimizados para consultas r√°pidas

##  Estructura de Archivos

```
fraud_detector_r4/
‚îú‚îÄ‚îÄ env.template              # Template de variables de entorno globales
‚îú‚îÄ‚îÄ .env                       # Variables de entorno globales (NO en git)
‚îú‚îÄ‚îÄ env.d/                     # Variables de entorno por servicio
‚îÇ   ‚îú‚îÄ‚îÄ zookeeper.env         # Variables de Zookeeper
‚îÇ   ‚îú‚îÄ‚îÄ kafka.env             # Variables de Kafka
‚îÇ   ‚îú‚îÄ‚îÄ schema-registry.env   # Variables de Schema Registry
‚îÇ   ‚îú‚îÄ‚îÄ kafka-connect.env     # Variables de Kafka Connect
‚îÇ   ‚îú‚îÄ‚îÄ ksqldb-server.env     # Variables de ksqlDB
‚îÇ   ‚îú‚îÄ‚îÄ postgres.env          # Variables de PostgreSQL
‚îÇ   ‚îú‚îÄ‚îÄ adminer.env           # Variables de Adminer
‚îÇ   ‚îú‚îÄ‚îÄ kafka-ui.env          # Variables de Kafka UI
‚îÇ   ‚îî‚îÄ‚îÄ README.md             # Documentaci√≥n de env.d/
‚îú‚îÄ‚îÄ setup.sh                   # Script principal de setup
‚îú‚îÄ‚îÄ generate_test_data.py      # Generador de datos
‚îú‚îÄ‚îÄ docker-compose.yml         # Configuraci√≥n de contenedores
‚îú‚îÄ‚îÄ connectors/                # Configuraci√≥n de conectores
‚îú‚îÄ‚îÄ ksqldb/                    # Scripts de ksqlDB
‚îú‚îÄ‚îÄ postgres/                  # Scripts de PostgreSQL
‚îú‚îÄ‚îÄ scripts/                   # Scripts auxiliares
‚îú‚îÄ‚îÄ data/                      # Datos (input/processed/error)
‚îî‚îÄ‚îÄ README.md                  # Este archivo
```

---

**Desarrollado para el ecosistema Apache Kafka**

##  Archivos de Referencia

### Configuraci√≥n
- **env.template**: Template completo de variables de entorno con todos los valores por defecto
- **create-env.sh**: Script interactivo para crear y configurar el archivo .env
